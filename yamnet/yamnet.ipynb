{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":142598,"sourceType":"datasetVersion","datasetId":3151}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport pandas as pd \nimport torch.optim as optim\nimport torch.nn.functional as F\nimport numpy as np\nfrom torch.utils.data import DataLoader\nimport torchvision.models as models\nimport torchaudio\nimport torchaudio.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nimport librosa\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport os\nimport torchaudio.transforms as T\nimport random","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T22:46:06.218494Z","iopub.execute_input":"2024-10-18T22:46:06.219297Z","iopub.status.idle":"2024-10-18T22:46:08.559583Z","shell.execute_reply.started":"2024-10-18T22:46:06.219246Z","shell.execute_reply":"2024-10-18T22:46:08.557809Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport torch\nimport numpy as np\nimport tensorflow_hub as hub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T22:46:13.787927Z","iopub.execute_input":"2024-10-18T22:46:13.788449Z","iopub.status.idle":"2024-10-18T22:46:13.796434Z","shell.execute_reply.started":"2024-10-18T22:46:13.788399Z","shell.execute_reply":"2024-10-18T22:46:13.795258Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"Id = []\n\nfor dirname, _, filenames in os.walk('/kaggle/input/environmental-sound-classification-50/audio/audio/16000'):\n    for filename in filenames:\n        Id.append(os.path.join(dirname, filename))\n    break\n    \ntrain_paths, test_paths = train_test_split(Id, test_size=0.2, random_state=42)\nId[:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T22:46:18.562351Z","iopub.execute_input":"2024-10-18T22:46:18.562765Z","iopub.status.idle":"2024-10-18T22:46:20.996690Z","shell.execute_reply.started":"2024-10-18T22:46:18.562719Z","shell.execute_reply":"2024-10-18T22:46:20.995542Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"['/kaggle/input/environmental-sound-classification-50/audio/audio/16000/5-257349-A-15.wav',\n '/kaggle/input/environmental-sound-classification-50/audio/audio/16000/5-195557-A-19.wav',\n '/kaggle/input/environmental-sound-classification-50/audio/audio/16000/2-122820-B-36.wav',\n '/kaggle/input/environmental-sound-classification-50/audio/audio/16000/1-115920-A-22.wav',\n '/kaggle/input/environmental-sound-classification-50/audio/audio/16000/1-172649-C-40.wav']"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# inputs = {ort_session.get_inputs()[0].name: w}\n# outputs = ort_session.run(None, inputs)\n\n# # Get the 3 outputs\n# class_scores = outputs[0]  # Class predictions (521 classes)\n# embeddings = outputs[1]    # Embeddings (feature vector)\n# logit_predictions = outputs[2]  # Logits","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = pd.DataFrame({'filename':train_paths })\ntrain.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T22:46:28.404255Z","iopub.execute_input":"2024-10-18T22:46:28.405049Z","iopub.status.idle":"2024-10-18T22:46:28.424003Z","shell.execute_reply.started":"2024-10-18T22:46:28.405008Z","shell.execute_reply":"2024-10-18T22:46:28.422793Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                            filename\n0  /kaggle/input/environmental-sound-classificati...\n1  /kaggle/input/environmental-sound-classificati...\n2  /kaggle/input/environmental-sound-classificati...\n3  /kaggle/input/environmental-sound-classificati...\n4  /kaggle/input/environmental-sound-classificati...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/environmental-sound-classificati...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/environmental-sound-classificati...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/environmental-sound-classificati...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/environmental-sound-classificati...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/environmental-sound-classificati...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"len(train['filename'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T22:46:36.866665Z","iopub.execute_input":"2024-10-18T22:46:36.867052Z","iopub.status.idle":"2024-10-18T22:46:36.874644Z","shell.execute_reply.started":"2024-10-18T22:46:36.867018Z","shell.execute_reply":"2024-10-18T22:46:36.873258Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"1600"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# for signature in yamnet_model.signatures:\n#     print(f\"Signature: {signature}\")\n#     print(yamnet_model.signatures[signature].structured_outputs)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train['label'] = train['filename'].apply(lambda x: int(os.path.basename(x).split('-')[-1].split('.')[0]))\nprint(train[['filename', 'label']].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T22:46:44.452952Z","iopub.execute_input":"2024-10-18T22:46:44.453503Z","iopub.status.idle":"2024-10-18T22:46:44.475749Z","shell.execute_reply.started":"2024-10-18T22:46:44.453450Z","shell.execute_reply":"2024-10-18T22:46:44.474472Z"}},"outputs":[{"name":"stdout","text":"                                            filename  label\n0  /kaggle/input/environmental-sound-classificati...      2\n1  /kaggle/input/environmental-sound-classificati...     34\n2  /kaggle/input/environmental-sound-classificati...     44\n3  /kaggle/input/environmental-sound-classificati...     20\n4  /kaggle/input/environmental-sound-classificati...     22\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"test = pd.DataFrame({'filename':test_paths })\ntest['label'] = test['filename'].apply(lambda x: int(os.path.basename(x).split('-')[-1].split('.')[0]))\nprint(test[['filename', 'label']].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T22:46:53.442470Z","iopub.execute_input":"2024-10-18T22:46:53.442895Z","iopub.status.idle":"2024-10-18T22:46:53.454304Z","shell.execute_reply.started":"2024-10-18T22:46:53.442853Z","shell.execute_reply":"2024-10-18T22:46:53.453085Z"}},"outputs":[{"name":"stdout","text":"                                            filename  label\n0  /kaggle/input/environmental-sound-classificati...     29\n1  /kaggle/input/environmental-sound-classificati...     37\n2  /kaggle/input/environmental-sound-classificati...      8\n3  /kaggle/input/environmental-sound-classificati...     47\n4  /kaggle/input/environmental-sound-classificati...      7\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# criterion = nn.CrossEntropyLoss()\n# optimizer = optim.Adam(yamnet_model.parameters(), lr=1e-4)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Augmentation\n\n# def add_white_noise( x, noise_percentage_factor):\n#     noise = np.random.normal(0, x.std(), x.size)\n#     return x + noise * noise_percentage_factor\n\n# # def stime_stretch( x, time_stretch_rate):\n# #         return librosa.effects.time_stretch(x, time_stretch_rate)\n# # def add_time_stretch(x, time_stretch_rate):\n# #     return librosa.effects.time_stretch(x, time_stretch_rate)\n# def pitch_scale( x, sr, num_semitones):\n#     return librosa.effects.pitch_shift(x, sr, num_semitones)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/environmental-sound-classification-50/esc50.csv')\n\npd.set_option('display.max_columns', None)\n\nprint(df.head())  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T22:47:01.746517Z","iopub.execute_input":"2024-10-18T22:47:01.746919Z","iopub.status.idle":"2024-10-18T22:47:01.769734Z","shell.execute_reply.started":"2024-10-18T22:47:01.746880Z","shell.execute_reply":"2024-10-18T22:47:01.768693Z"}},"outputs":[{"name":"stdout","text":"            filename  fold  target        category  esc10  src_file take\n0   1-100032-A-0.wav     1       0             dog   True    100032    A\n1  1-100038-A-14.wav     1      14  chirping_birds  False    100038    A\n2  1-100210-A-36.wav     1      36  vacuum_cleaner  False    100210    A\n3  1-100210-B-36.wav     1      36  vacuum_cleaner  False    100210    B\n4  1-101296-A-19.wav     1      19    thunderstorm  False    101296    A\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"classes = dict(zip(df['target'], df['category']))\n\nprint(classes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T22:47:10.394043Z","iopub.execute_input":"2024-10-18T22:47:10.395039Z","iopub.status.idle":"2024-10-18T22:47:10.400902Z","shell.execute_reply.started":"2024-10-18T22:47:10.394995Z","shell.execute_reply":"2024-10-18T22:47:10.399696Z"}},"outputs":[{"name":"stdout","text":"{0: 'dog', 14: 'chirping_birds', 36: 'vacuum_cleaner', 19: 'thunderstorm', 30: 'door_wood_knock', 34: 'can_opening', 9: 'crow', 22: 'clapping', 48: 'fireworks', 41: 'chainsaw', 47: 'airplane', 31: 'mouse_click', 17: 'pouring_water', 45: 'train', 8: 'sheep', 15: 'water_drops', 46: 'church_bells', 37: 'clock_alarm', 32: 'keyboard_typing', 16: 'wind', 25: 'footsteps', 4: 'frog', 3: 'cow', 27: 'brushing_teeth', 43: 'car_horn', 12: 'crackling_fire', 40: 'helicopter', 29: 'drinking_sipping', 10: 'rain', 7: 'insects', 26: 'laughing', 6: 'hen', 44: 'engine', 23: 'breathing', 20: 'crying_baby', 49: 'hand_saw', 24: 'coughing', 39: 'glass_breaking', 28: 'snoring', 18: 'toilet_flush', 2: 'pig', 35: 'washing_machine', 38: 'clock_tick', 21: 'sneezing', 1: 'rooster', 11: 'sea_waves', 42: 'siren', 5: 'cat', 33: 'door_wood_creaks', 13: 'crickets'}\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from audiomentations import Compose, AddGaussianNoise, PitchShift, HighPassFilter\n\n# from helper import _plot_signal_and_augmented_signal\n\n# install pydub for using HighPassFilter\n# install audiomentations\n\n# Raw audio augmentation\naugment_raw_audio = Compose(\n    [\n#         AddGaussianNoise(min_amplitude=0.01, max_amplitude=0.015, p=1),\n        PitchShift(min_semitones=-8, max_semitones=8, p=1),\n        HighPassFilter(min_cutoff_freq=2000, max_cutoff_freq=4000, p=1)\n    ]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T22:47:20.541627Z","iopub.execute_input":"2024-10-18T22:47:20.542023Z","iopub.status.idle":"2024-10-18T22:47:28.371805Z","shell.execute_reply.started":"2024-10-18T22:47:20.541988Z","shell.execute_reply":"2024-10-18T22:47:28.370771Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"!pip install tf2onnx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T22:48:05.246192Z","iopub.execute_input":"2024-10-18T22:48:05.246650Z","iopub.status.idle":"2024-10-18T22:48:18.588952Z","shell.execute_reply.started":"2024-10-18T22:48:05.246608Z","shell.execute_reply":"2024-10-18T22:48:18.587559Z"}},"outputs":[{"name":"stdout","text":"Collecting tf2onnx\n  Downloading tf2onnx-1.16.1-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: numpy>=1.14.1 in /opt/conda/lib/python3.10/site-packages (from tf2onnx) (1.26.4)\nRequirement already satisfied: onnx>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from tf2onnx) (1.17.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from tf2onnx) (2.32.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from tf2onnx) (1.16.0)\nRequirement already satisfied: flatbuffers>=1.12 in /opt/conda/lib/python3.10/site-packages (from tf2onnx) (24.3.25)\nRequirement already satisfied: protobuf~=3.20 in /opt/conda/lib/python3.10/site-packages (from tf2onnx) (3.20.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->tf2onnx) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->tf2onnx) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->tf2onnx) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->tf2onnx) (2024.8.30)\nDownloading tf2onnx-1.16.1-py3-none-any.whl (455 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.8/455.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tf2onnx\nSuccessfully installed tf2onnx-1.16.1\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"!pip install torch onnx onnxruntime\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T22:48:21.213610Z","iopub.execute_input":"2024-10-18T22:48:21.214071Z","iopub.status.idle":"2024-10-18T22:48:34.225711Z","shell.execute_reply.started":"2024-10-18T22:48:21.214028Z","shell.execute_reply":"2024-10-18T22:48:34.224536Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0+cpu)\nRequirement already satisfied: onnx in /opt/conda/lib/python3.10/site-packages (1.17.0)\nCollecting onnxruntime\n  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from onnx) (1.26.4)\nRequirement already satisfied: protobuf>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from onnx) (3.20.3)\nCollecting coloredlogs (from onnxruntime)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (24.3.25)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (21.3)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->onnxruntime) (3.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nDownloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\nSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.19.2\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"!mkdir -p saved_model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T22:48:44.713596Z","iopub.execute_input":"2024-10-18T22:48:44.714041Z","iopub.status.idle":"2024-10-18T22:48:45.754781Z","shell.execute_reply.started":"2024-10-18T22:48:44.713998Z","shell.execute_reply":"2024-10-18T22:48:45.753348Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"concrete_func = yamnet_model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n\n# Save the model with the concrete function\ntf.saved_model.save(yamnet_model, 'saved_model/yamnet_model', signatures=concrete_func)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T22:48:51.211202Z","iopub.execute_input":"2024-10-18T22:48:51.212049Z","iopub.status.idle":"2024-10-18T22:48:55.560862Z","shell.execute_reply.started":"2024-10-18T22:48:51.211997Z","shell.execute_reply":"2024-10-18T22:48:55.559815Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"!python -m tf2onnx.convert --saved-model saved_model/yamnet_model --output yamnet.onnx\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T22:52:37.486450Z","iopub.execute_input":"2024-10-18T22:52:37.486884Z","iopub.status.idle":"2024-10-18T22:52:53.005755Z","shell.execute_reply.started":"2024-10-18T22:52:37.486849Z","shell.execute_reply":"2024-10-18T22:52:53.004407Z"}},"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/runpy.py:126: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n  warn(RuntimeWarning(msg))\n2024-10-18 22:52:42,464 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n2024-10-18 22:52:47,783 - INFO - Signatures found in model: [serving_default].\n2024-10-18 22:52:47,783 - WARNING - '--signature_def' not specified, using first signature: serving_default\n2024-10-18 22:52:47,784 - INFO - Output names: ['output_0', 'output_1', 'output_2']\n2024-10-18 22:52:49,620 - INFO - Using tensorflow=2.16.1, onnx=1.17.0, tf2onnx=1.16.1/15c810\n2024-10-18 22:52:49,621 - INFO - Using opset <onnx, 15>\n2024-10-18 22:52:49,797 - INFO - Computed 0 values for constant folding\n2024-10-18 22:52:50,257 - INFO - Optimizing ONNX model\n2024-10-18 22:52:51,947 - INFO - After optimization: BatchNormalization -27 (27->0), Cast -8 (19->11), Concat -3 (14->11), Const -169 (260->91), GlobalAveragePool +1 (0->1), Identity -6 (6->0), ReduceMean -1 (1->0), Reshape -17 (26->9), Shape -1 (4->3), Slice -1 (4->3), Transpose -121 (124->3), Unsqueeze -13 (21->8)\n2024-10-18 22:52:51,978 - INFO - \n2024-10-18 22:52:51,978 - INFO - Successfully converted TensorFlow model saved_model/yamnet_model to ONNX\n2024-10-18 22:52:51,978 - INFO - Model inputs: ['waveform']\n2024-10-18 22:52:51,978 - INFO - Model outputs: ['output_0', 'output_1', 'output_2']\n2024-10-18 22:52:51,978 - INFO - ONNX model is saved at yamnet.onnx\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import onnxruntime as ort\nimport numpy as np\nimport librosa\n\n# Load ONNX model\nort_session = ort.InferenceSession('yamnet.onnx')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T22:52:55.976720Z","iopub.execute_input":"2024-10-18T22:52:55.977742Z","iopub.status.idle":"2024-10-18T22:52:56.095558Z","shell.execute_reply.started":"2024-10-18T22:52:55.977691Z","shell.execute_reply":"2024-10-18T22:52:56.094470Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def ensure_sample_rate(original_sample_rate, waveform, desired_sample_rate=16000):\n    \"\"\"Resample waveform if required using PyTorch.\"\"\"\n    if original_sample_rate != desired_sample_rate:\n        resample_transform = torchaudio.transforms.Resample(orig_freq=original_sample_rate, new_freq=desired_sample_rate)\n        waveform = resample_transform(waveform)\n    return desired_sample_rate, waveform # sr and signal\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T22:53:12.435280Z","iopub.execute_input":"2024-10-18T22:53:12.435692Z","iopub.status.idle":"2024-10-18T22:53:12.441468Z","shell.execute_reply.started":"2024-10-18T22:53:12.435653Z","shell.execute_reply":"2024-10-18T22:53:12.440307Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def extract_embeddings(filename):\n    y, sr = librosa.load(filename, sr=22050)\n\n    s,w=ensure_sample_rate(sr, y, desired_sample_rate=22050)\n    inputs = {ort_session.get_inputs()[0].name: w}\n    outputs = ort_session.run(None, inputs)\n    class_scores = outputs[0]  # Class predictions (521 classes)\n    embeddings = outputs[1]    # Embeddings (feature vector)\n    logit_predictions = outputs[2]  # Logits\n    return class_scores, embeddings\nall_embeddings = []\nall_labels = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T22:53:27.222273Z","iopub.execute_input":"2024-10-18T22:53:27.222693Z","iopub.status.idle":"2024-10-18T22:53:27.229472Z","shell.execute_reply.started":"2024-10-18T22:53:27.222656Z","shell.execute_reply":"2024-10-18T22:53:27.228195Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"for i in range(len(train)):\n        \n        filename, label = train['filename'][i],  train['label'][i]\n        c,e=extract_embeddings(filename)\n        all_embeddings.append(e)\n        all_labels.append(label)\nall_embeddings = np.array(all_embeddings)  # Shape: (num_samples, 1024)\nall_labels = np.array(all_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T22:53:37.595446Z","iopub.execute_input":"2024-10-18T22:53:37.595849Z","iopub.status.idle":"2024-10-18T22:54:58.299464Z","shell.execute_reply.started":"2024-10-18T22:53:37.595810Z","shell.execute_reply":"2024-10-18T22:54:58.298094Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# for epoch in range(5):\n#     avg_loss, accuracy = train(model, criterion, optimizer, train_loader,device )\n#     print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Define a simple fully connected classifier in PyTorch\nclass Classifier(nn.Module):\n    def __init__(self, input_dim, num_classes):\n        super(Classifier, self).__init__()\n        self.fc = nn.Linear(input_dim, num_classes)\n\n    def forward(self, x):\n        return self.fc(x)\n\n# Instantiate the classifier for ESC-50 (50 classes)\ninput_dim = 1024  # YAMNet embeddings are 1024-D\nnum_classes = 50  # ESC-50 has 50 classes\nmodel = Classifier(input_dim, num_classes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T22:55:03.340972Z","iopub.execute_input":"2024-10-18T22:55:03.342028Z","iopub.status.idle":"2024-10-18T22:55:03.365419Z","shell.execute_reply.started":"2024-10-18T22:55:03.341983Z","shell.execute_reply":"2024-10-18T22:55:03.364347Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split embeddings into training and testing sets (80-20 split)\nX_train, X_test, y_train, y_test = train_test_split(all_embeddings, all_labels, test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T22:55:32.166477Z","iopub.execute_input":"2024-10-18T22:55:32.166874Z","iopub.status.idle":"2024-10-18T22:55:32.204331Z","shell.execute_reply.started":"2024-10-18T22:55:32.166840Z","shell.execute_reply":"2024-10-18T22:55:32.203166Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\ny_train_tensor = torch.tensor(y_train, dtype=torch.long)\nX_test_tensor = torch.tensor(X_test, dtype=torch.float32)\ny_test_tensor = torch.tensor(y_test, dtype=torch.long)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T22:55:40.828913Z","iopub.execute_input":"2024-10-18T22:55:40.829803Z","iopub.status.idle":"2024-10-18T22:55:40.883664Z","shell.execute_reply.started":"2024-10-18T22:55:40.829754Z","shell.execute_reply":"2024-10-18T22:55:40.882781Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nnum_epochs = 100\n\nfor epoch in range(num_epochs):\n    model.train()\n    optimizer.zero_grad()\n\n    # Forward pass\n    outputs = model(X_train_tensor)\n    outputs = outputs.mean(dim=1)  # Shape becomes [1280, 50]\n    loss = criterion(outputs, y_train_tensor)\n    loss.backward()\n    optimizer.step()\n\n    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T23:06:42.214698Z","iopub.execute_input":"2024-10-18T23:06:42.216537Z","iopub.status.idle":"2024-10-18T23:06:42.225905Z","shell.execute_reply.started":"2024-10-18T23:06:42.216486Z","shell.execute_reply":"2024-10-18T23:06:42.224614Z"}},"outputs":[{"name":"stdout","text":"\nepoch:  0 loss:  1.0146068847465515 accuracy:  46.704 %\n---------------------------\nepoch:  1 loss:  0.7963647353076935 accuracy:  52.76599999999999 %\n---------------------------\nepoch:  2 loss:  0.7743401646614074 accuracy:  53.76 %\n saved at /kaggle/working/cnnnet_epoch_3.pth\n---------------------------\nepoch:  3 loss:  0.7466917690753937 accuracy:  54.276 %\n---------------------------\nepoch:  5 loss:  0.7228994320201874 accuracy:  55.234 %\n saved at /kaggle/working/cnnnet_epoch_6.pth\n---------------------------\nepoch:  6 loss:  0.7195748014545441 accuracy:  55.468 %\n---------------------------\nepoch:  7 loss:  0.7127152788257599 accuracy:  55.554 %\n---------------------------\nepoch:  8 loss:  0.7048812763404846 accuracy:  55.928 %\n saved at /kaggle/working/cnnnet_epoch_9.pth\n---------------------------\nepoch:  9 loss:  0.6917364977455139 accuracy:  56.266 %\n---------------------------\nepoch:  10 loss:  0.6951166493034363 accuracy:  56.294 %\n---------------------------\nepoch:  11 loss:  0.6932430562496186 accuracy:  56.414 %\n saved at /kaggle/working/cnnnet_epoch_12.pth\n---------------------------\nepoch:  12 loss:  0.6938887001800537 accuracy:  56.346 %\n---------------------------\nepoch:  16 loss:  0.6774496854972839 accuracy:  56.88000000000001 %\n---------------------------\nepoch:  17 loss:  0.6849525020980834 accuracy:  56.766 %\n saved at /kaggle/working/cnnnet_epoch_18.pth\n---------------------------\nepoch:  18 loss:  0.6732319131088257 accuracy:  57.008 %\n---------------------------\nepoch:  19 loss:  0.673291750459671 accuracy:  57.03999999999999 %\n---------------------------\nfinished training\n\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# Test\n\nwith torch.no_grad():\n    model.eval()\n    total_loss=0.0 \n    total_correct=0.0 \n    for inputs, labels in testloader:\n        labels=labels.to(device)\n        outputs=model(inputs.to(device))\n        loss=criterion(outputs, labels)\n        total_loss+=loss.item()*inputs.size(0)\n        output_idx=torch.argmax(outputs, dim=1)\n        total_correct+=sum(labels==output_idx).sum().item() \n        accuracy = (total_correct / test_len) * 100\n        loss = total_loss / test_len\n\n    print(f'Accuracy: {accuracy:.2f}% Loss: {loss:.4f}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T23:17:31.312607Z","iopub.execute_input":"2024-10-18T23:17:31.313061Z","iopub.status.idle":"2024-10-18T23:17:31.319862Z","shell.execute_reply.started":"2024-10-18T23:17:31.313022Z","shell.execute_reply":"2024-10-18T23:17:31.318617Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 72.06% Loss: 0.5240\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}